{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ALL_STATES = ['ACT', 'NSW', 'NT', 'QLD', 'SA', 'TAS', 'VIC', 'WA']\n",
    "\n",
    "# Load postcodes data\n",
    "df = pd.read_csv('data/postcodes/australian_postcodes.csv', dtype={'locality': str, 'state': str, 'postcode': str})\n",
    "df2 = pd.read_csv('data/postcodes/postcode-dataout.txt', header=None, names=['suburb', 'state', 'postcode'], dtype={'suburb': str, 'state': str, 'postcode': str})\n",
    "\n",
    "# Clean postcodes data\n",
    "df.rename(columns={'locality': 'name'}, inplace=True)\n",
    "df2.rename(columns={'suburb': 'name'}, inplace=True)\n",
    "df['name'] = df['name'].str.upper()\n",
    "df['state'] = df['state'].str.upper()\n",
    "df2['name'] = df2['name'].str.upper()\n",
    "df2['state'] = df2['state'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfs_states = []\n",
    "for state in ALL_STATES:\n",
    "    \n",
    "    state_lower = state.lower()\n",
    "    \n",
    "    gdf_state : gpd.GeoDataFrame = gpd.read_file(f'data/geojson/suburb-10-{state_lower}.geojson')\n",
    "    \n",
    "    new_column_names = {}\n",
    "    for old_column in gdf_state.columns:\n",
    "        old_column : str\n",
    "        column = old_column\n",
    "        column = column.replace(f'{state_lower}_', '')\n",
    "        column = column.replace(f'loca_', 'local_')\n",
    "        column = column.replace(f'localit', 'locali')\n",
    "        column = column.replace(f'locali', 'locality')\n",
    "        new_column_names[old_column] = column\n",
    "\n",
    "    gdf_state['state'] = state\n",
    "\n",
    "    gdf_state = gdf_state.rename(columns=new_column_names).to_crs('EPSG:4326')\n",
    "    \n",
    "    gdfs_states.append(gdf_state)\n",
    "\n",
    "\n",
    "# Full N/A: local_1 local_3 local_6\n",
    "# No N/A: local_2 local_5 local_7\n",
    "# Some N/A: local_4\n",
    "# loc_pid is not unique\n",
    "# lc_ply_pid is not unique\n",
    "# id is unique\n",
    "\n",
    "gdf = gpd.GeoDataFrame(pd.concat(gdfs_states, ignore_index=True))\n",
    "gdf.rename(columns={'locality': 'dt_locality', 'local_2' : 'name', 'local_4' : 'postcode'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf[['name', 'state', 'postcode', 'local_5', 'lc_ply_pid', 'loc_pid', 'dt_create', 'dt_locality', 'id', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ids_gdf(long, lat):\n",
    "    '''\n",
    "    Find the list of ids of all rows in gdf that contain the coordinate\n",
    "    '''\n",
    "    return gdf[gdf.contains(gpd.GeoSeries([Point(long, lat)]).unary_union)]['id'].tolist()\n",
    "\n",
    "def find_ids_df(gdf_row_geometry):\n",
    "    '''\n",
    "    Find the list of ids of all rows in df where the gdf_row contains the coordinate\n",
    "    gdf_row is a row in gdf\n",
    "    '''\n",
    "    return df[df.apply(lambda row: gdf_row_geometry.contains(Point(row['long'], row['lat'])), axis=1)]['id'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polygon_ids'] = df.apply(lambda row: find_ids_gdf(row['long'], row['lat']), axis=1)\n",
    "# 3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polygon_precise'] = df.apply(lambda row: find_ids_gdf(row['Long_precise'], row['Lat_precise']), axis=1)\n",
    "# 4m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_postcode_pair = df[['id', 'polygon_ids']].explode('polygon_ids').dropna()\n",
    "polygon_postcode_pair_precise = df[['id', 'polygon_precise']].explode('polygon_precise').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_postcode = polygon_postcode_pair.groupby('polygon_ids').agg({'id': list}).reset_index().rename(columns={'id': 'ps', 'polygon_ids': 'id'})\n",
    "polygon_postcode_precise = polygon_postcode_pair_precise.groupby('polygon_precise').agg({'id': list}).reset_index().rename(columns={'id': 'ps_precise', 'polygon_precise': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf : gpd.GeoDataFrame = gpd.read_file('suburbs.geojson')\n",
    "gdf['postcode'] = gdf['postcode'].apply(lambda x: x.split(', ') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.merge(polygon_postcode, left_on='id', right_on='id', how='left')\n",
    "gdf = gdf.merge(polygon_postcode_precise, left_on='id', right_on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform df into : { id: [name, state, postcode], ... }\n",
    "id_to_data = df[['id', 'name', 'state', 'postcode']].set_index('id').apply(lambda x: x.to_list(), axis=1).to_dict()\n",
    "id_to_postcode = df[['id', 'postcode']].set_index('id').to_dict()['postcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf['ps_len'] = gdf['ps'].apply(lambda x: len(x) if isinstance(x, list) else x)\n",
    "gdf['ps_precise_len'] = gdf['ps_precise'].apply(lambda x: len(x) if isinstance(x, list) else x)\n",
    "gdf['ps1'] = gdf['ps'].apply(lambda x: [id_to_data[i] for i in x] if isinstance(x, list) else np.nan)\n",
    "gdf['ps1_precise'] = gdf['ps_precise'].apply(lambda x: [id_to_data[i] for i in x] if isinstance(x, list) else np.nan)\n",
    "gdf['psp'] = gdf['ps'].apply(lambda x: list(set(id_to_postcode[i] for i in x)) if isinstance(x, list) else np.nan)\n",
    "gdf['psp_precise'] = gdf['ps_precise'].apply(lambda x: list(set(id_to_postcode[i] for i in x)) if isinstance(x, list) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf['postcode'].isna()][['name','state','postcode','ps1','ps1_precise', 'ps_len', 'ps_precise_len']].to_csv('missing-postcodes-analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[['name', 'state', 'postcode', 'local_5', 'lc_ply_pid', 'loc_pid', 'dt_create', 'dt_locality', 'psp','psp_precise', 'ps_len', 'ps_precise_len', 'id']].to_csv('suburbs-postcodes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
